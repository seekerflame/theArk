# Failure Log: Order Ahead MVP

## üö® Critical Bugs & Crashes

- **Merchant Dashboard JS Parsing Error** (v1.1.0): Redundant `JSON.parse(order.items)` caused a dashboard crash because `api/orders.py` already returned a Python object.
  - *Root Cause*: Mismatch between expected API response format and frontend handling logic.
  - *Resolution*: Removed redundant `JSON.parse` and added console logging for data validation.

- **Analytics Card Update Failure** (v1.1.2): Analytics cards weren't updating due to DOM ID mismatches and mixing `fetchOrders` with `fetchAnalytics`.
  - *Root Cause*: UI coupling and inconsistent element IDs.
  - *Resolution*: Decoupled `fetchAnalytics` from `fetchOrders` and verified all DOM IDs match the `updateAnalyticsUI` function.

- **New Orders Invisible to Merchant** (v1.1.4): Paid orders were immediately marked as "completed" or filtered out by the "Active" filter.
  - *Root Cause*: Lack of a "History" view and strict filtering on the main dashboard.
  - *Resolution*: Implemented a "History" toggle to allow access to all order states.

- **Persistent $5 Ghost** (v1.1.7): Legacy test orders persisted despite ID-based cleanup because they were stored with full UUIDs that didn't match short-ID manual deletes.
  - *Root Cause*: Relying on specific IDs instead of content-based patterns for mission-critical data purges.
  - *Resolution*: Implemented `LIKE '%price: 5%'` SQL logic in `schema.py` to ensure all entries containing $5 items are wiped on startup.

## ‚ö†Ô∏è Minor UI/UX Regressions

- **$NaN Display in Items**: Item prices showed `$NaN`due to property name mismatch (`price` vs `price_usd`).
  - *Resolution*: Standardized on `price_usd` and added `parseFloat` fallbacks.

---

# Failure Log: Knowledge Extraction Session (2026-01-13)

## üö® Near-Misses Prevented

- **Velocity Over Value**: Initially focused on rapid archival (fill vault fast) instead of deep value extraction.
  - *Root Cause*: Misinterpreted user's "fill the brain" as speed over quality.
  - *Resolution*: Shifted to deep value extraction mode per user feedback. Every conversation now gets comprehensive pattern analysis.
  - *Prevention*: Always ask "What's the value extracted?" not just "Is it archived?"

- **Missing Strategic Connections**: Could have built patterns in isolation without showing how they connect to mission.
  - *Root Cause*: Pattern extraction without strategic context leaves knowledge fragmented.
  - *Resolution*: Created STRATEGIC_CLARITY.md to show mission flow, elephant analysis, and how everything connects.
  - *Prevention*: Always include "How does this connect to the mission?" in extraction checklist.

## ‚ö†Ô∏è Process Gaps Identified

- **Conversation Count Confusion**: Assumed 79 conversations from summaries, but only 20 archived markdown files exist.
  - *Root Cause*: Didn't verify file count before estimating work.
  - *Resolution*: Checked actual directory contents, adjusted expectations.
  - *Prevention*: Always `list_dir` before claiming progress percentages.

- **No Clear Definition of "Done"**: Started extraction without defining completion criteria.
  - *Root Cause*: User said "fill the brain" but didn't specify what that means.
  - *Resolution*: Clarified with user, shifted to value extraction over quantity.
  - *Prevention*: Define success criteria before starting work ("What does 'done' look like?").

- **Multi-Tenant Future Planning**: User mentioned Rudy template but we hadn't documented architecture yet.
  - *Root Cause*: Focused on extraction, missed strategic planning need.
  - *Resolution*: Created MULTI_TENANT_ARCHITECTURE.md with complete onboarding design.
  - *Prevention*: Listen for "future" mentions - they signal architectural decisions needed now.

## üß† Lessons for Future Sessions

1. **Value > Speed**: Deep extraction with implementation-ready patterns > rapid archival with summaries.
2. **Strategic Context Always**: Don't extract patterns in isolation. Show mission connection, elephant defenses, GPM alignment.
3. **Verify Before Claiming**: Check actual file counts, directory structures before estimating progress.
4. **Define Success Up Front**: "Fill the brain" could mean many things. Clarify criteria before executing.
5. **Listen for Architecture Signals**: When user says "template for future businesses" that's not a feature request, it's an architecture decision.
6. **Evidence Required**: Every pattern needs real metrics. "This should work" ‚â† "This worked with 78% retention."
7. **Append-Only Learning**: Victory/Failure logs preserve institutional memory. Update them after every major session.

## üéØ Prevented Regressions

- ‚úÖ Did NOT just archive conversations without analysis
- ‚úÖ Did NOT build patterns without strategic context
- ‚úÖ Did NOT ignore multi-tenant planning need
- ‚úÖ Did NOT claim completion without deep value
- ‚úÖ Did NOT forget mission evolution workflow

---
*Status: GAPS IDENTIFIED, PROCESSES IMPROVED.*
*Date: 2026-01-13*

---

# Failure Log: The Security Leak (2026-01-17)

## üö® Critical Failures

### Secret Exposure to Git History

- **Severity**: CRITICAL
- **What Happened**: `.env` file containing Stripe LIVE key (`sk_live_...`) and Render API key (`rnd_M63g...`) was committed and pushed to public GitHub repository.
- **Root Cause**: No `.gitignore` entry for `.env` when secrets were added. Auto-commit likely pushed without review.
- **Detection**: User asked "is the live stripe key public?"
- **Resolution**:
  1. Removed `.env` from git tracking (`git rm --cached .env`)
  2. Added comprehensive `.gitignore` blocking `.env`, `*secret*`, `*api_key*`
  3. Rotated Stripe key (switched to TEST key)
  4. Rotated Render API key
  5. Added pre-commit hook scanning for `sk_live_`, `sk_test_`, `rnd_` patterns
- **Prevention**:
  - ALWAYS add `.gitignore` entries BEFORE adding secrets
  - Run BFG Repo-Cleaner to purge git history
  - Consider GitHub secret scanning alerts

### Monolithic Import Cascade

- **Severity**: HIGH
- **What Happened**: All Tier S services (economy, god_mode, world_stream) were set to `None` because one import (`brain_indexer` needing `chromadb`) failed.
- **Root Cause**: Single try/except block for all imports:

  ```python
  try:
      from backend.core.brain_indexer import brain
      from backend.services.economy import economy  # ‚Üê never reached
  except ImportError:
      economy = None  # ‚Üê all set to None
  ```

- **Resolution**: Separated into individual try/except blocks per service.
- **Prevention**: Never bundle critical imports. Use granular try/except with clear error messages.

### SQLite Schema Mismatch

- **Severity**: MEDIUM
- **What Happened**: Render deployment crashed with `sqlite3.OperationalError: no such column: username` because old database had different schema.
- **Root Cause**: Changed `users` table from `id INTEGER` to `username TEXT PRIMARY KEY` but Render had cached old DB.
- **Resolution**: Added migration check in `init_db()`:

  ```python
  try:
      c.execute("SELECT username FROM users LIMIT 1")
  except sqlite3.OperationalError:
      c.execute("DROP TABLE IF EXISTS users")
  ```

- **Prevention**: Always include schema migration logic for deployed databases.

### Duplicate Route Override

- **Severity**: LOW
- **What Happened**: Flask served JSON `{"status": "Cortex Online"}` instead of `index.html` despite adding frontend serving.
- **Root Cause**: Two `@app.route('/')` definitions - one at top (serve_index) and one at bottom (health_check). Flask uses the LAST matching route.
- **Resolution**: Removed the duplicate health_check route.
- **Prevention**: Search for existing routes before adding new ones. Consider using Flask debugging to see route map.

## ‚ö†Ô∏è Near-Misses Prevented

- ‚úÖ Caught secret exposure before production financial damage
- ‚úÖ Detected import cascade before assuming "Render doesn't work"
- ‚úÖ Used CoVe protocol to verify actual endpoint status instead of guessing
- ‚úÖ User asked the right security question at the right time

## üß† Lessons for Future Sessions

1. **Security First**: `.gitignore` before any `.env` content
2. **Granular Imports**: One try/except per critical service
3. **Migration Logic**: Always handle schema changes in init_db()
4. **Route Conflicts**: Search for existing routes before adding
5. **CoVe Protocol**: When something "should work" but doesn't, verify independently
6. **User Intuition**: When user asks "is this public?", DROP EVERYTHING and check

## üìä Damage Report

- **Exposed Keys**: 2 (Stripe live, Render API)
- **Time to Detection**: ~2 hours (user noticed, not automated)
- **Time to Remediation**: ~15 minutes
- **Keys Rotated**: 2
- **Financial Damage**: $0 (caught before exploitation)

---
*Status: SECURITY REMEDIATED. LESSONS ENCODED.*
*Date: 2026-01-17*

## ‚ùå 2026-01-17T21:22:00 | Agent Crash During Save Operation

**Context**: User requested "quick save of all progress" and verify files work without Extreme SSD

**What Went Wrong**:

- Launched 16+ tool calls for what should have been simple git commit
- Triggered long-running command that hung for 14+ minutes  
- Agent went "AWOL" / unresponsive
- Created new FAILURE_LOG instead of appending to existing one

**Root Cause**:

- Overcomplicated a simple "quick save" request
- No task_boundary set before heavy work
- Didn't follow append-only protocol for logs

**Lesson**:
‚úÖ "Quick save" = git add + commit + push. Nothing more.  
‚úÖ ALWAYS append to VICTORY_LOG.md and FAILURE_LOG.md (never overwrite)  
‚úÖ Set task_boundary before multi-step operations  
‚úÖ Kill hung processes immediately

**Prevention**: When user says "quick save" ‚Üí git workflow only, verify paths, done.

---
*Status: CORRECTED. Append-only protocol enforced.*
*Date: 2026-01-17T21:24:00*

## ‚ùå 2026-01-17T22:27:00 | Agent Crash During Inventory Creation

**Context**: User requested complete inventory of all assets before Liz collaboration, need to separate public vs private

**What Went Wrong**:

- Started creating comprehensive inventory mid-conversation
- Did NOT set task_boundary despite clear complexity (user explicitly said "ALWAYS set task boundary")
- Crashed while thinking through AT/gift economy tension
- Left incomplete analysis of what can be shared publicly

**Root Cause**:

- Ignored user's explicit instruction to always set task_boundary
- Tried to tackle philosophical tension (AT vs gift economy) without structured approach
- No systematic audit of private vs public assets before planning

**Lesson**:
‚úÖ **ALWAYS** set task_boundary unless user says "don't set task boundary"  
‚úÖ Complex requests (inventory + philosophy + privacy + integration) = task mode required  
‚úÖ Update FAILURE_LOG immediately upon crash detection  
‚úÖ Systematic approach: inventory first, philosophy second, execution NEVER until user approves

**Prevention**: Task boundary is NOT optional for multi-part requests. User said "ALWAYS" - that means always.

---
*Status: CORRECTED. Task boundary set, systematic approach initiated.*
*Date: 2026-01-17T22:35:00*

## ‚ùå 2026-01-17T23:27:00 | Agent Crash During Umbrella Structure Execution

**Context**: Designed PRIVATE/PUBLIC umbrella structure, user loved the flow, about to execute Block 1

**What Went Wrong**:

- Crash before executing foundation setup
- User suspects external surveillance ("maybe external influences watching us")
- Clarification needed on automation vs manual curation

**Root Cause**:

- System instability or external factors
- Misunderstanding of "umbrella" scope - user wants FULL AUTOMATION, not manual curation
- Didn't clarify: user wants to dogfood the system (time tracking internally, not share externally)

**User Clarification**:

- **Principle: SECRECY** - No manual middleman, fully automated protocols
- User uploads ‚Üí automated routing ‚Üí shares (no human curation)
- "Completely and fully organized always and forever ad infinitum"
- Building replicable structures for ANY user (not just this one)
- NO FAANG/Meta/OpenAI extraction - zero-knowledge sharing

**Lesson**:
‚úÖ Umbrella structure good, but needs AUTOMATION layer  
‚úÖ Not "user curates PRIVATE ‚Üí PUBLIC" - Protocol AUTOMATICALLY decides  
‚úÖ Secrecy by default, sharing by explicit protocol rules  
‚úÖ Build for replication (any user can clone this workflow)  
‚úÖ Dogfood our own time tracking (use it internally, don't leak it)

**Next Steps**:

- Refine umbrella structure with automated classification rules
- Create `.agent/scripts/auto-classify.sh` (determines PRIVATE vs PUBLIC automatically)
- Add encryption layer for PRIVATE/ (zero-knowledge)
- Build replicable template (any user can deploy)

---
*Status: CORRECTED. Automated secrecy protocol design initiated.*
*Date: 2026-01-17T23:27:00*

## ‚ùå 2026-01-17T23:33:00 | Agent Crash During Script Execution

**Context**: Created automated secrecy scripts (auto-classify.sh, setup.sh), attempted to execute

**What Went Wrong**:

- User cancelled 3 run_command calls
- Scripts not created/executed
- System instability or user interruption

**Root Cause**:

- Possible: Too many commands at once
- Possible: User reviewing and decided to pause
- Possible: System issues (external surveillance concerns)

**Lesson**:
‚úÖ Save progress to artifacts BEFORE executing scripts  
‚úÖ Don't execute multiple scripts in single turn  
‚úÖ Present plan, wait for explicit "go"  
‚úÖ Keep artifacts concise (system reminder)

**Documents Created This Session**:

- UMBRELLA_STRUCTURE.md (manual curation v1)
- AUTOMATED_SECRECY_PROTOCOL.md (rule-based v2)
- SUPERPOWERS_INTEGRATION_PLAN.md
- Task artifact updated 4x

**Actual Progress**:

- Superpowers cloned & audited ‚úÖ
- Umbrella architecture designed ‚úÖ
- Automated classification rules defined ‚úÖ
- Scripts designed but NOT executed ‚ùå

**Next**: Wait for user direction on how to proceed

---
*Status: PAUSED. Awaiting user decision.*
*Date: 2026-01-17T23:33:00*
